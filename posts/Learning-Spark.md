---
title: "Learning Spark"
date: "2019-01-24"
---

<div class="content">
<p>I’m learning <a href="https://spark.apache.org/" target="_blank">Apache Spark</a> for a work project and of the “big data” systems I’ve looked at, it’s my favorite so far.</p>
<p>I was pretty disappointed with how little assistance it provides the developer in terms of making parallel computing transparent (vs. HPC tools &amp; languages) but it has its charms.</p>
<p>In any event the biggest barrier for me so far has been getting my head around the <a href="https://en.wikipedia.org/wiki/MapReduce" target="_blank">MapReduce</a> programming model.  My first professional experience in working with data was SQL/RDBMS-oriented and a few years back I started working with key-value stores, but I never really embraced MapReduce, so now I’m paying for that.</p>
<p>It’s frustrating to be held-back from reaching a goal or solving a problem that you could solve quickly using what you know because you have to learn something new, but on the flip-side I <em>love</em> learning new things, so I’m trying really hard to frame this process with a focus on learning how to adopt the <em>philosophy</em> of Spark &amp; MapReduce and not trying to simply force the models I’m comfortable with onto this new environment (having been on the receiving end of that kind of force, I can appreciate why it’s a bad idea).</p>
<p>Another exciting aspect about this is that it gives me a very practical application for the <a href="/tags/rain">RAIN</a> project.  Spark is probably not a perfect fit for a machine like RAIN since Spark is really oriented to data-bound processing and RAIN is more constrained in the storage/memory resources than a more traditional server farm, but if nothing else it will give me a more practical workload to experiment vs. benchmarks.</p>
<p>(it also gives me an excuse to wrench on RAIN during “business hours”)</p>
</div>
